# ğŸ  La Maison - Web Scraping Project

## ğŸ“‹ Vue d'ensemble

Un outil de scraping robuste dÃ©veloppÃ© avec Scrapy pour extraire des donnÃ©es de produits d'un site e-commerce. Le projet est conÃ§u pour parcourir automatiquement des catÃ©gories dÃ©finies et collecter des informations dÃ©taillÃ©es sur les produits.

## âœ¨ FonctionnalitÃ©s principales

- ğŸ”„ Extraction automatisÃ©e des donnÃ©es produits
- ğŸ“‘ Lecture des catÃ©gories depuis un fichier CSV
- ğŸ” Collecte dÃ©taillÃ©e (nom, prix, marque, etc.)
- ğŸ“Š Pipeline de traitement des donnÃ©es
- ğŸš¦ Gestion intelligente de la pagination
- insertion dans une base de donnÃ©es
- Application en streamlit qui permet de :
  -  Lancer le scraping des catÃ©gories et des produits
  -  Affichage des produits avec diffÃ©rents filtres (catÃ©gorie, sous catÃ©gorie, promotion ...) et de chercher un produit avec un mot clÃ©.

## ğŸš€ Installation

1. Clonez le dÃ©pÃ´t :
```bash
git clone https://github.com/Malek-Boumedine/brief_scraping_la_maison.git
cd la_maison
```

2. Installez les dÃ©pendances :
```bash
pip install -r requirements.txt
```

## âš™ï¸ Configuration

### PrÃ©requis
- Python 3.7+
- Fichier `categories.csv` dans le rÃ©pertoire racine

### Configuration du Pipeline
```python
ITEM_PIPELINES = {
   'la_maison.pipelines.LaMaisonPipeline': 300,
}
```

## ğŸ“¦ Structure du projet

```
la_maison/
â”œâ”€â”€ spiders/          # Spiders Scrapy
â”œâ”€â”€ pipelines.py      # Pipelines de traitement
â”œâ”€â”€ settings.py       # Configuration
â”œâ”€â”€ items.py         # DÃ©finition des items
â””â”€â”€ requirements.txt  # DÃ©pendances
```

## ğŸ¯ Utilisation

Lancer le scraping :
```bash
scrapy crawl spider/spider_categories.py
scrapy crawl spider/spider_produits.py
```
### On peut aussi lancer le runner pour chaque spider

## ğŸ“ Bonnes pratiques

- â±ï¸ Configurez des dÃ©lais entre requÃªtes
- ğŸ›¡ï¸ ImplÃ©mentez la gestion d'erreurs
- ğŸ“Š Validez les donnÃ©es extraites

## ğŸ¤ Contribution

1. Fork du projet
2. CrÃ©ation de branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. CrÃ©ation d'une Pull Request

## ğŸ“š Documentation

- [Documentation Scrapy](https://docs.scrapy.org/)
- [Guide d'utilisation](./docs/USAGE.md)
- [Guide de contribution](./docs/CONTRIBUTING.md)

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“§ Contact

Pour toute question : [mon_email@gmail.com](mailto:email@example.com)

---

## ğŸ™ Remerciements

Merci Ã  tous les contributeurs qui ont participÃ© Ã  l'amÃ©lioration de ce projet.
